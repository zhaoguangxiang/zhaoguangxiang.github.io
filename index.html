
<!doctype html>
<html>
<head>
<meta charset="utf-8">
<title>Zhao Guangxiang(Peking University)</title>
<style type="text/css">
.name {font-size: 24px;}
body {background-color: #FFF;}
body,td,th {font-size: 22px;}
.size20 {font-size: 22px;
}
.new_tag {
	font-family: "Arial Black", Gadget, sans-serif;
	color: #F00;
}
</style>
<style type="text/css" rel="stylesheet">
a{
color:color:blue;text-decoration:none;
}
a:hover{
color:#A52A2A;text-decoration:none;
}
a:active{
color:blue;text-decoration:none;
}
</style>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131156519-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	    gtag('config', 'UA-131156519-1');
		</script>

<script>
function copy(dest, source) {
  if(dest.source == source) {
    dest.innerHTML = "";
    dest.source = null;
  }
  else {
    dest.innerHTML = source.innerHTML;
    dest.source = source;
  }
  dest.blur();
}
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>

</head>

<table cellspacing="0" cellpadding="0" border="0" width="1200">
<tr>
<td width="16%" height="120"><img src="6.jpg" width="180" /></td>

<td width="84%">
<body>
 <p><strong>Guangxiang Zhao (赵光香）</strong></p>
 <p>Ph.D Student, <a href="https://eecs.pku.edu.cn/index.htm">School of EECS</a>, <a href="https://www.pku.edu.cn/">Peking University</a></p>
 <p>I am doing research at <br> <a href="https://lancopku.github.io/">Language Computing and Machine Learning Group (LANCO)</a>, <br> advised by Prof. <a href="https://xusun.org/">Xu SUN</a>.</p>
<!-- <p><a href="https://tobiaslee.top">Blog</a> <br> -->
  <a href="https://github.com/zhaoguangxiang">GitHub</a> <br>
  <a href="https://twitter.com/GuangxiangZ">Twitter</a> <br>
  <a href='https://scholar.google.com/citations?user=0IXhrDMAAAAJ&hl=zh-CN'>Google Scholar</a><br>
 <a href="https://openreview.net/profile?id=~guangxiang_zhao2&mode=view">OpenReview</a> <br>
  <p>Email: zhaoguangxiang at pku.edu.cn / guangxiangzhao at gmail.com</p>
</td>
 
</tr>
</table>
 
<p style="font-size: 12px; height: 5px">&nbsp;</p>
 <h3>Research Interests:</h3>
<p>Learning methods for natural language generation. </p>

<h3>Service:</h3>
<ul>
<li>
As a reviewer at ACL Rolling Review, ICLR-2022, ACL-2021, TNNLS <br>
<li>
As a teach assistant for "Foudations of Computer Science for Art Special", "Introduction to Natural Language Processing" <br>
<div id="ACL_2018d" style="display:none">
<blockquote>
</blockquote>
</div>
</ul>

	
	
<h3>Papers: </h3>
<ul>
	
<li>
Well-classified Examples are Underestimated in Classification with Deep Neural Networks <br>
<b> Guangxiang Zhao</b>, Wenkai Yang, Xuancheng Ren, Lei Li, Xu Sun.  <br>
AAAI 2022 <br>
TL;DR: In this paper, we find that the cross-entropy loss hinders representation learning, energy optimization, and margin growth, while well-classified examples play a vital role to solving these issues.  <br>
<a href=https://arxiv.org/abs/2110.06537>[pdf]</a> <a href=https://github.com/lancopku/well-classified-examples-are-underestimated>[code] </a>
<br><br>
	
				<li>
Topology-Imbalance Learning for Semi-Supervised Node Classification <br>
Deli Chen, Yankai Lin, <b> Guangxiang Zhao</b>, Xuancheng Ren, Peng Li, Jie Zhou, Xu Sun.  <br>
NeurIPS 2021 <br>
TL;DR: We identify the probelm of Topology-Imbalance and propose the ReNode method as the initial solution. <br>
<a href=https://arxiv.org/abs/2110.04099>[pdf]</a> <a href=https://github.com/victorchen96/ReNode>[code] </a>
<br><br>
		
			<li>
Learning Relation Alignment for Calibrated Cross-modal Retrieval <br>
Shuhuai Ren, Junyang Lin, <b> Guangxiang Zhao</b>, Rui Men, An Yang, Jingren Zhou, Xu Sun, Hongxia Yang. <br>
ACL 2021 <br>
TL;DR: We propose the idea of relation alignment that aligns self-attention among two modalities. <br>
 <a https://aclanthology.org/2021.acl-long.43.pdf>[pdf]</a> <a href=https://github.com/lancopku/IAIS>[code] </a>
<br><br>
				
	<li>
Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning <br>
Fenglin Liu*, Xuancheng Ren* (Equal Contribution), <b>Guangxiang Zhao</b>, Xu Sun <br>
Preprint 2020 <br>
TL;DR: We find a limitation about information flow in Transformer and propose an effective cross-view decoding method to solve it. <br>
<a href=https://arxiv.org/pdf/2005.08081>[pdf]</a>
<br><br>		

						<li>
Understanding and Improving Layer Normalization <br>
Jingjing Xu, Xu Sun, Zhiyuan Zhang,<b> Guangxiang Zhao</b>, Junyang Lin. <br>
NeurIPS 2019 <br>
TL;DR:We find that the backprop of layernorm is essential and propose a better normalization method. <br>
<a href=https://papers.nips.cc/paper/8689-understanding-and-improving-layer-normalization>[pdf]</a> <a href=https://github.com/lancopku/AdaNorm>[code] </a>
<br><br>
			
	<li>
Parallel Intersected Multi-scale Attention for Sequence to Sequence Learning <br>
<b>Guangxiang Zhao</b>, Xu Sun, Jingjing Xu,  Zhiyuan Zhang, Liangcheng Luo. <br>
Preprint 2019 <br>
TL;DR: We propose a simple module Prime that consistently outperforms the complicated Transformer model on main NMT datasets with SOTA performance by simply stacking this module; We also find that when combine the convolution and self-attention, their operations for learning interactions between tokens should be performed on the same features. <br>

<a href=https://arxiv.org/abs/1911.09483>[pdf]</a> <a href=https://github.com/lancopku/Prime>[code, scripts, and pretrained models] </a>
<br><br>
		
			<li>
Explicit Sparse Transformer <br>
<b>Guangxiang Zhao</b>, Junyang Lin, Zhiyuan Zhang, Xuancheng Ren, Qi Su, Xu Sun. <br>
Preprint 2019 <br>
TL;DR: We propose a sparse attention method without local dependency constraint or the need of predefined sparse attention patterns; We demonstrate that sparse attention (8 or 1/4 of the sequence length(30) in NMT) is better than regular attention.  <br>

<a href=https://arxiv.org/pdf/1912.11637>[pdf]</a> <a href=https://github.com/lancopku/Explicit-Sparse-Transformer>[code] </a>
<br><br>

	
<li>
Review-Driven Multi-Label Music Style Classification by Exploiting Style Correlations <br>
<b>Guangxiang Zhao*</b>, Jingjing Xu* (Equal Contribution), Qi Zeng, Xuancheng Ren, Xu Sun.<br>
NAACL 2019 <br>
TL;DR: We build a multi-label text classification dataset (music styles are hidden in the text) with strong label correlations, propose a method that automatically learns and exploits labels correlation during training. <br>
	
<a href=https://www.aclweb.org/anthology/N19-1296.pdf>[pdf]</a> <a href=https://github.com/lancopku/RMSC>[data] </a>
<br><br>

	
		
<div id="ACL_2018d" style="display:none">
<blockquote>
</blockquote>
</div>
</ul>

<h3>Awards:</h3>
<ul>
<li>
Merit Student of Peking University, 2019 <br>
<div id="ACL_2018d" style="display:none">
<blockquote>
</blockquote>
</div>
</ul>


</body>
</html>
